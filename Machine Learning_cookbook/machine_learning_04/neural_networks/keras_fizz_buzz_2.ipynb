{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viki/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/viki/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets limit input to 16 digits\n",
    "INPUT_DIGITS = 16\n",
    "number_of_numbers = 2 ** INPUT_DIGITS - 1\n",
    "input_number = []\n",
    "output_label = []\n",
    "for i in range(1, number_of_numbers):\n",
    "    input_number.append(i)\n",
    "    if i % 3 == 0 and i % 5 == 0:\n",
    "        output_label.append(0) # fizzbuzz\n",
    "    elif i % 3 == 0:\n",
    "        output_label.append(1) # fizz\n",
    "    elif i % 5 == 0:\n",
    "        output_label.append(2) # buzz\n",
    "    else:\n",
    "        output_label.append(3) # Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_input_numer_to_binary(num):\n",
    "    binary_rep = list(\"{0:b}\".format(num))\n",
    "    final_res = ['0' for _ in range(INPUT_DIGITS)]\n",
    "    for idx, v in enumerate(reversed(binary_rep)):\n",
    "        final_res[idx] = v\n",
    "    return list(reversed(final_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_map_binary_to_number(binary):\n",
    "    return int(''.join(binary), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0'] 2\n"
     ]
    }
   ],
   "source": [
    "print(map_input_numer_to_binary(2), reverse_map_binary_to_number(map_input_numer_to_binary(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([map_input_numer_to_binary(v) for v in input_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49150, 16), (16384, 16), (49150, 4), (16384, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44235 samples, validate on 4915 samples\n",
      "Epoch 1/100\n",
      "44235/44235 [==============================] - 2s 38us/step - loss: 1.1500 - acc: 0.5303 - val_loss: 1.1552 - val_acc: 0.5284\n",
      "Epoch 2/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 1.1406 - acc: 0.5337 - val_loss: 1.1521 - val_acc: 0.5284\n",
      "Epoch 3/100\n",
      "44235/44235 [==============================] - 1s 32us/step - loss: 1.1385 - acc: 0.5337 - val_loss: 1.1524 - val_acc: 0.5284\n",
      "Epoch 4/100\n",
      "44235/44235 [==============================] - 1s 31us/step - loss: 1.1381 - acc: 0.5337 - val_loss: 1.1515 - val_acc: 0.5284\n",
      "Epoch 5/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 1.1366 - acc: 0.5337 - val_loss: 1.1475 - val_acc: 0.5284\n",
      "Epoch 6/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 1.1339 - acc: 0.5337 - val_loss: 1.1475 - val_acc: 0.5284\n",
      "Epoch 7/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 1.1307 - acc: 0.5337 - val_loss: 1.1420 - val_acc: 0.5284\n",
      "Epoch 8/100\n",
      "44235/44235 [==============================] - 1s 27us/step - loss: 1.1223 - acc: 0.5336 - val_loss: 1.1261 - val_acc: 0.5284\n",
      "Epoch 9/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 1.0966 - acc: 0.5385 - val_loss: 1.0858 - val_acc: 0.5563\n",
      "Epoch 10/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 1.0408 - acc: 0.6002 - val_loss: 1.0133 - val_acc: 0.6427\n",
      "Epoch 11/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.9571 - acc: 0.6407 - val_loss: 0.9636 - val_acc: 0.6370\n",
      "Epoch 12/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.8604 - acc: 0.6709 - val_loss: 0.8306 - val_acc: 0.6832\n",
      "Epoch 13/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.7635 - acc: 0.7211 - val_loss: 0.7175 - val_acc: 0.7434\n",
      "Epoch 14/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.6716 - acc: 0.7622 - val_loss: 0.6376 - val_acc: 0.7829\n",
      "Epoch 15/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.5997 - acc: 0.7923 - val_loss: 0.5526 - val_acc: 0.8051\n",
      "Epoch 16/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.5336 - acc: 0.8211 - val_loss: 0.5012 - val_acc: 0.8264\n",
      "Epoch 17/100\n",
      "44235/44235 [==============================] - 1s 22us/step - loss: 0.4773 - acc: 0.8459 - val_loss: 0.4461 - val_acc: 0.8625\n",
      "Epoch 18/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.4233 - acc: 0.8682 - val_loss: 0.3990 - val_acc: 0.8859\n",
      "Epoch 19/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.3807 - acc: 0.8824 - val_loss: 0.3706 - val_acc: 0.8850\n",
      "Epoch 20/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.3424 - acc: 0.8953 - val_loss: 0.3152 - val_acc: 0.9027\n",
      "Epoch 21/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.3094 - acc: 0.9040 - val_loss: 0.2979 - val_acc: 0.9207\n",
      "Epoch 22/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.2819 - acc: 0.9129 - val_loss: 0.2674 - val_acc: 0.9284\n",
      "Epoch 23/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.2613 - acc: 0.9173 - val_loss: 0.2460 - val_acc: 0.9229\n",
      "Epoch 24/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.2444 - acc: 0.9226 - val_loss: 0.2244 - val_acc: 0.9294\n",
      "Epoch 25/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.2257 - acc: 0.9296 - val_loss: 0.2061 - val_acc: 0.9327\n",
      "Epoch 26/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.2128 - acc: 0.9332 - val_loss: 0.2094 - val_acc: 0.9432\n",
      "Epoch 27/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.1998 - acc: 0.9381 - val_loss: 0.1930 - val_acc: 0.9375\n",
      "Epoch 28/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.1883 - acc: 0.9408 - val_loss: 0.1790 - val_acc: 0.9451\n",
      "Epoch 29/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.1770 - acc: 0.9447 - val_loss: 0.1686 - val_acc: 0.9473\n",
      "Epoch 30/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.1671 - acc: 0.9486 - val_loss: 0.1805 - val_acc: 0.9438\n",
      "Epoch 31/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.1601 - acc: 0.9503 - val_loss: 0.1517 - val_acc: 0.9599\n",
      "Epoch 32/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.1503 - acc: 0.9545 - val_loss: 0.1508 - val_acc: 0.9626\n",
      "Epoch 33/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.1416 - acc: 0.9568 - val_loss: 0.1446 - val_acc: 0.9652\n",
      "Epoch 34/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.1305 - acc: 0.9620 - val_loss: 0.1379 - val_acc: 0.9587\n",
      "Epoch 35/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.1251 - acc: 0.9631 - val_loss: 0.1098 - val_acc: 0.9699\n",
      "Epoch 36/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.1151 - acc: 0.9673 - val_loss: 0.1118 - val_acc: 0.9687\n",
      "Epoch 37/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.1156 - acc: 0.9653 - val_loss: 0.1118 - val_acc: 0.9760\n",
      "Epoch 38/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.1050 - acc: 0.9704 - val_loss: 0.1130 - val_acc: 0.9693\n",
      "Epoch 39/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.1005 - acc: 0.9717 - val_loss: 0.1315 - val_acc: 0.9577\n",
      "Epoch 40/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.1000 - acc: 0.9716 - val_loss: 0.0902 - val_acc: 0.9756\n",
      "Epoch 41/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0946 - acc: 0.9731 - val_loss: 0.1110 - val_acc: 0.9725\n",
      "Epoch 42/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0889 - acc: 0.9748 - val_loss: 0.0756 - val_acc: 0.9774\n",
      "Epoch 43/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0820 - acc: 0.9776 - val_loss: 0.0743 - val_acc: 0.9792\n",
      "Epoch 44/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0816 - acc: 0.9772 - val_loss: 0.0976 - val_acc: 0.9697\n",
      "Epoch 45/100\n",
      "44235/44235 [==============================] - 1s 28us/step - loss: 0.0794 - acc: 0.9784 - val_loss: 0.0670 - val_acc: 0.9839\n",
      "Epoch 46/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0759 - acc: 0.9791 - val_loss: 0.0660 - val_acc: 0.9835\n",
      "Epoch 47/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0715 - acc: 0.9803 - val_loss: 0.0763 - val_acc: 0.9833\n",
      "Epoch 48/100\n",
      "44235/44235 [==============================] - 1s 27us/step - loss: 0.0711 - acc: 0.9808 - val_loss: 0.0617 - val_acc: 0.9845\n",
      "Epoch 49/100\n",
      "44235/44235 [==============================] - 2s 35us/step - loss: 0.0665 - acc: 0.9825 - val_loss: 0.0718 - val_acc: 0.9835\n",
      "Epoch 50/100\n",
      "44235/44235 [==============================] - 2s 34us/step - loss: 0.0626 - acc: 0.9835 - val_loss: 0.0580 - val_acc: 0.9870\n",
      "Epoch 51/100\n",
      "44235/44235 [==============================] - 1s 33us/step - loss: 0.0637 - acc: 0.9824 - val_loss: 0.0767 - val_acc: 0.9697\n",
      "Epoch 52/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0629 - acc: 0.9829 - val_loss: 0.0635 - val_acc: 0.9821\n",
      "Epoch 53/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0552 - acc: 0.9862 - val_loss: 0.0492 - val_acc: 0.9896\n",
      "Epoch 54/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0546 - acc: 0.9867 - val_loss: 0.0545 - val_acc: 0.9866\n",
      "Epoch 55/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0541 - acc: 0.9863 - val_loss: 0.0640 - val_acc: 0.9825\n",
      "Epoch 56/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0514 - acc: 0.9867 - val_loss: 0.0484 - val_acc: 0.9882\n",
      "Epoch 57/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0509 - acc: 0.9880 - val_loss: 0.0606 - val_acc: 0.9780\n",
      "Epoch 58/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0505 - acc: 0.9870 - val_loss: 0.0409 - val_acc: 0.9913\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0456 - acc: 0.9889 - val_loss: 0.0511 - val_acc: 0.9858\n",
      "Epoch 60/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0472 - acc: 0.9888 - val_loss: 0.0461 - val_acc: 0.9888\n",
      "Epoch 61/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0425 - acc: 0.9908 - val_loss: 0.0352 - val_acc: 0.9921\n",
      "Epoch 62/100\n",
      "44235/44235 [==============================] - 1s 27us/step - loss: 0.0447 - acc: 0.9889 - val_loss: 0.0323 - val_acc: 0.9929\n",
      "Epoch 63/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0411 - acc: 0.9903 - val_loss: 0.0493 - val_acc: 0.9860\n",
      "Epoch 64/100\n",
      "44235/44235 [==============================] - 1s 27us/step - loss: 0.0427 - acc: 0.9900 - val_loss: 0.0361 - val_acc: 0.9915\n",
      "Epoch 65/100\n",
      "44235/44235 [==============================] - 1s 27us/step - loss: 0.0400 - acc: 0.9909 - val_loss: 0.0331 - val_acc: 0.9935\n",
      "Epoch 66/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0367 - acc: 0.9921 - val_loss: 0.0305 - val_acc: 0.9927\n",
      "Epoch 67/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.0392 - acc: 0.9908 - val_loss: 0.0359 - val_acc: 0.9902\n",
      "Epoch 68/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0365 - acc: 0.9913 - val_loss: 0.0278 - val_acc: 0.9947\n",
      "Epoch 69/100\n",
      "44235/44235 [==============================] - 1s 28us/step - loss: 0.0318 - acc: 0.9934 - val_loss: 0.0319 - val_acc: 0.9929\n",
      "Epoch 70/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0339 - acc: 0.9923 - val_loss: 0.0320 - val_acc: 0.9921\n",
      "Epoch 71/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0315 - acc: 0.9936 - val_loss: 0.0355 - val_acc: 0.9908\n",
      "Epoch 72/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0314 - acc: 0.9937 - val_loss: 0.0380 - val_acc: 0.9896\n",
      "Epoch 73/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0334 - acc: 0.9922 - val_loss: 0.0432 - val_acc: 0.9900\n",
      "Epoch 74/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0353 - acc: 0.9917 - val_loss: 0.0369 - val_acc: 0.9866\n",
      "Epoch 75/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0322 - acc: 0.9925 - val_loss: 0.0284 - val_acc: 0.9927\n",
      "Epoch 76/100\n",
      "44235/44235 [==============================] - 1s 26us/step - loss: 0.0309 - acc: 0.9930 - val_loss: 0.0238 - val_acc: 0.9945\n",
      "Epoch 77/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0272 - acc: 0.9941 - val_loss: 0.0209 - val_acc: 0.9965\n",
      "Epoch 78/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0274 - acc: 0.9944 - val_loss: 0.0253 - val_acc: 0.9951\n",
      "Epoch 79/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0250 - acc: 0.9953 - val_loss: 0.0196 - val_acc: 0.9965\n",
      "Epoch 80/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.0282 - acc: 0.9940 - val_loss: 0.0215 - val_acc: 0.9976\n",
      "Epoch 81/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0307 - acc: 0.9930 - val_loss: 0.0184 - val_acc: 0.9980\n",
      "Epoch 82/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0248 - acc: 0.9953 - val_loss: 0.0219 - val_acc: 0.9955\n",
      "Epoch 83/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0229 - acc: 0.9959 - val_loss: 0.0212 - val_acc: 0.9951\n",
      "Epoch 84/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.0276 - acc: 0.9942 - val_loss: 0.0461 - val_acc: 0.9890\n",
      "Epoch 85/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.0247 - acc: 0.9952 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "Epoch 86/100\n",
      "44235/44235 [==============================] - 1s 23us/step - loss: 0.0245 - acc: 0.9949 - val_loss: 0.0192 - val_acc: 0.9963\n",
      "Epoch 87/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0289 - acc: 0.9931 - val_loss: 0.0540 - val_acc: 0.9833\n",
      "Epoch 88/100\n",
      "44235/44235 [==============================] - 1s 29us/step - loss: 0.0262 - acc: 0.9942 - val_loss: 0.0208 - val_acc: 0.9955\n",
      "Epoch 89/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0239 - acc: 0.9947 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "Epoch 90/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0239 - acc: 0.9947 - val_loss: 0.0134 - val_acc: 0.9980\n",
      "Epoch 91/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0192 - acc: 0.9967 - val_loss: 0.0222 - val_acc: 0.9951\n",
      "Epoch 92/100\n",
      "44235/44235 [==============================] - 1s 27us/step - loss: 0.0263 - acc: 0.9938 - val_loss: 0.0140 - val_acc: 0.9988\n",
      "Epoch 93/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0224 - acc: 0.9954 - val_loss: 0.0171 - val_acc: 0.9967\n",
      "Epoch 94/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0262 - acc: 0.9938 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 95/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0184 - acc: 0.9964 - val_loss: 0.0123 - val_acc: 0.9980\n",
      "Epoch 96/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0257 - acc: 0.9941 - val_loss: 0.0146 - val_acc: 0.9982\n",
      "Epoch 97/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0196 - acc: 0.9965 - val_loss: 0.0179 - val_acc: 0.9969\n",
      "Epoch 98/100\n",
      "44235/44235 [==============================] - 1s 24us/step - loss: 0.0207 - acc: 0.9960 - val_loss: 0.0177 - val_acc: 0.9963\n",
      "Epoch 99/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0184 - acc: 0.9964 - val_loss: 0.0178 - val_acc: 0.9969\n",
      "Epoch 100/100\n",
      "44235/44235 [==============================] - 1s 25us/step - loss: 0.0189 - acc: 0.9962 - val_loss: 0.0168 - val_acc: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121867c88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_shape=(16,)))\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU(alpha=0.3))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(keras.layers.advanced_activations.LeakyReLU(alpha=0.3))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974365234375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(predictions, axis=1), np.argmax(y_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sample(input_value, output_prediction, expected_ouput, no_of_sampels=5, print_values=False):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for value, pred, expected in zip(input_value, output_prediction, expected_ouput):\n",
    "        val = reverse_map_binary_to_number(value)\n",
    "        pred_val = np.argmax(pred)\n",
    "        expected_val = np.argmax(expected)\n",
    "        if print_values: print(val, pred_val, expected_val) # To prevent printing all values\n",
    "        if expected_val == pred_val:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "        if no_of_sampels and count >= no_of_sampels:\n",
    "            break\n",
    "    print('correct', correct/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56698 3 3\n",
      "27266 3 3\n",
      "62738 3 3\n",
      "58929 1 1\n",
      "50762 3 3\n",
      "59504 3 3\n",
      "57471 1 1\n",
      "27106 3 3\n",
      "18344 3 3\n",
      "61343 3 3\n",
      "correct 1.0\n"
     ]
    }
   ],
   "source": [
    "print_sample(x_val, predictions, y_val, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
