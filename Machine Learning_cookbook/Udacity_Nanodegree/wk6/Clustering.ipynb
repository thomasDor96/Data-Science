{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 6. Clustering Miniproject\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "  - Perform k-means clustering on the Enron Data Set.  \n",
    "  - Visualize different clusters that form before and after feature scaling.  \n",
    "  - Plot decision boundaries that arise from k-means clustering using two features.   \n",
    "  \n",
    "### Prerequisites\n",
    "  - [matplotlib](http://matplotlib.org/index.html)  \n",
    "  - [numpy](http://www.scipy.org/scipylib/download.html)  \n",
    "  - [pandas](http://pandas.pydata.org/getpandas.html)  \n",
    "  - [sklearn](http://scikit-learn.org/stable/install.html)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 | Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the Enron datasets. Here is more information about the [Enron scandal](https://en.wikipedia.org/wiki/Enron_scandal). The datasets can be found in the [ud120-projects repo](https://github.com/udacity/ud120-projects) on GitHub. The datasets are in **pickled** form. \n",
    "\n",
    "### `pickle`\n",
    "\n",
    "Suppose you're working with Python and you assemble nice data structures (*e.g.* dictionaries, lists, tuples, sets...) that you'll want to re-use in Python at a later time. [The `pickle` module](https://docs.python.org/2/library/pickle.html) is a fast, efficient way to preserve (or pickle) those data structures without you needing to worry about how to structure or organize your output file. One nice thing about using `pickle` is that the data structures you store can be arbitrarily complex: you can have nested data structures (*e.g.* lists of tuples as the values in a dictionary) and `pickle` will know exactly how to serialize (or write) those structures to file. The next time you're in Python, you can un-pickle the data structures using `pickle.load()` and pick up right where you left off.\n",
    "\n",
    "> Reference on `pickle`: [Serializing Python Objects](http://www.diveintopython3.net/serializing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pickle_file = open('./data/dataset.pkl', 'r')\n",
    "enron_data = pickle.load(pickle_file)\n",
    "pickle_file.close()\n",
    "print 'Enron data loaded successfully!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 | Data Preprocessing  \n",
    "\n",
    "We couldn't find *all* the information for each person involved with the Enron scandal, so the Enron dataset has some missing values denoted by `\"NaN\"` in the data dictionary. Because we must pass numeric arrays into `sklearn`, we need to preprocess the data dictionary a bit before we can use [`sklearn.cluster.KMeans()`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "**Run** the cell below to complete our preprocessing steps:\n",
    "  - Remove the outlier: there is an entry `\"TOTAL\"` in the data dictionary containing totals of all features.\n",
    "  - Create a pandas `DataFrame` object from the Enron data dictionary\n",
    "  - Take the **transpose** of the Enron `DataFrame` with [`DataFrame.T`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.T.html), so that rows correspond to individuals (instances). Recall that we used [`stack()` and `unstack()`](http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-by-stacking-and-unstacking) last time to accomplish this task... but taking the transpose is more straightforward.\n",
    "  - Impute missing values: Replace all \"NaN\" values in the DataFrame with **zeroes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Enron dataset:\n",
    "# there's an outlier--remove it! \n",
    "enron_data.pop('TOTAL', 0)\n",
    "\n",
    "# Create a DataFrame object from the Enron data dictionary\n",
    "enron_df = pd.DataFrame.from_dict(enron_data)\n",
    "\n",
    "# Take the transpose (.T) of the Enron DataFrame,\n",
    "# so that rows of the DataFrame correspond to individuals\n",
    "enron_df = enron_df.T\n",
    "\n",
    "# Change all entries in the DataFrame with \"NaN\" to zeroes.\n",
    "enron_df[enron_df == 'NaN'] = 0\n",
    "\n",
    "# Display the DataFrame after preprocessing is complete\n",
    "display(enron_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 | K-Means Clustering\n",
    "\n",
    "In this mini-project, you will perform [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) on the Enron dataset. We're going to define a function `DrawClusters()` that will allow us to visualize the resulting clusters. \n",
    "\n",
    "**Read** the cell below to get an idea of what happens in the `DrawClusters()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def DrawClusters(n_clusters = 2,\\\n",
    "                 feature_list = ['salary', 'exercised_stock_options'],\\\n",
    "                 remove_any_zeroes = False,\\\n",
    "                 remove_all_zeroes = True,\\\n",
    "                 rescale_features = False,\\\n",
    "                 x_label = 'Salary',\\\n",
    "                 y_label = 'Exercised Stock Options'):\n",
    "    \n",
    "    '''\n",
    "    Plots k-means clusters trained on a list of features from enron_df\n",
    "    @param n_clusters:        an integer, the number of clusters to form.\n",
    "    @param feature_list:      a list of strings, the features to use in KMeans clustering\n",
    "                              (first two features in the list will be plotted on x,y axes)\n",
    "                              if len(feature_list) == 2, decision boundaries will be plotted \n",
    "    @param remove_any_zeroes: a boolean, whether or not to remove points when clustering\n",
    "                              that contain ANY zeroes\n",
    "    @param remove_all_zeroes: a boolean, whether or not to remove points when clustering\n",
    "                              that contain ONLY zeroes\n",
    "    @param rescale_features:  a boolean, whether or not to rescale features from 0 to 1\n",
    "    @param x_label:           a string, the x-axis label of the plot\n",
    "    @param y_label:           a string, the y-axis label of the plot\n",
    "    '''\n",
    "\n",
    "    # Initialize color and shape lists for scatterplot\n",
    "    # Note: need to lengthen the color and shape lists if\n",
    "    #       you want to use more than 7 clusters.\n",
    "    color_list = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "    shape_list = ['^', 'o', 's', 'v', 'D', '<', 'h']\n",
    "    \n",
    "    # Initialize figure and axes:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # We are going to cluster the data using KMeans,\n",
    "    # based on the features from the parameter feature_list.\n",
    "    X = enron_df[feature_list]\n",
    "    \n",
    "    # We can see if clustering correctly identified POIs\n",
    "    y = enron_df['poi']\n",
    "    \n",
    "    # If desired, remove instances where ANY feature is zero\n",
    "    if remove_any_zeroes:\n",
    "        X = X[~(X.T == 0).any()]\n",
    "        \n",
    "    # If desired, remove instances where ALL features are zeroes\n",
    "    if remove_all_zeroes:\n",
    "        X = X[~(X.T == 0).all()]\n",
    "\n",
    "    # If desired, rescale features\n",
    "    if rescale_features:\n",
    "        for feature in X.columns:\n",
    "            min_feature = X[~(X[feature] == 0)][feature].min()\n",
    "            max_feature = X[~(X[feature] == 0)][feature].max()\n",
    "            range_feature = max_feature - min_feature\n",
    "            X[feature] = (X[feature] - min_feature)*1.0 / range_feature\n",
    "            \n",
    "    # If we removed any instances above, we need to keep \n",
    "    # only the corresponding instances in y (the POI Series)\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # By default, the first two features in the list are chosen\n",
    "    # as the x and y features.\n",
    "    x_feature = feature_list[0]\n",
    "    y_feature = feature_list[1]\n",
    "\n",
    "    # Determine the min & max values of x_feature, compute the range,\n",
    "    # and pad the minimum and maximum x values by 5% of the range\n",
    "    x_min, x_max = X[x_feature].min(), X[x_feature].max()\n",
    "    x_range = x_max - x_min\n",
    "    x_min -= x_range * 0.05\n",
    "    x_max += x_range * 0.05\n",
    "    \n",
    "    # Determine the min & max values of y_feature, compute the range,\n",
    "    # and pad the minimum and maximum y values by 5% of the range\n",
    "    y_min, y_max = X[y_feature].min(), X[y_feature].max()\n",
    "    y_range = y_max - y_min\n",
    "    y_min -= y_range * 0.05\n",
    "    y_max += y_range * 0.05\n",
    "    \n",
    "    # Compute k-means clustering.\n",
    "    kmns = KMeans(n_clusters = n_clusters).fit(X)\n",
    "\n",
    "    \n",
    "    # We can visualize the decision boundaries if the \n",
    "    # k-means clusters are formed from just two features\n",
    "    if len(feature_list) == 2:\n",
    "        # Return coordinate matrices xx and yy from arrays\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, num = 500),\\\n",
    "                             np.linspace(y_min, y_max, num = 500))\n",
    "\n",
    "        # Use the clustering to make a prediction for each point\n",
    "        # in the coordinate matrices, then reshape for plotting.\n",
    "        Z = kmns.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Plot semitransparent filled contours for the\n",
    "        # cluster decision boundaries\n",
    "        ax.contourf(xx, yy, Z,\\\n",
    "                    levels=list(np.arange(n_clusters+1)-0.5),\\\n",
    "                    colors=tuple(color_list[:n_clusters]),alpha=0.2)\n",
    "    \n",
    "    # Scatterplot all of the points in each cluster,\n",
    "    # with each cluster a different color and shape\n",
    "    pred = kmns.predict(X)\n",
    "    for cluster_idx in range(n_clusters):\n",
    "        X_cluster = X[pred == cluster_idx]\n",
    "        ax.scatter(X_cluster[x_feature], X_cluster[y_feature],\\\n",
    "                   s=30, marker = shape_list[cluster_idx],\\\n",
    "                   edgecolor='k', facecolor=color_list[cluster_idx], alpha=0.8)\n",
    "        \n",
    "    # Denote the centroids of each cluster with a white X\n",
    "    centers = kmns.cluster_centers_\n",
    "    if len(feature_list) == 2:\n",
    "        for center in centers:\n",
    "            ax.scatter(center[0],center[1],marker='x',facecolor='w',linewidth=3,s=50)\n",
    "            \n",
    "    # Set the title and axes labels, and adjust the aspect ratio for rescaled data\n",
    "    if rescale_features:\n",
    "        title   = ax.set_title('K Means - {} Clusters (Rescaled)'.format(n_clusters))\n",
    "        # Force the axes aspect ratio to be plotted equally\n",
    "        ax.set(adjustable='box-forced', aspect='equal')\n",
    "    else:\n",
    "        title   = ax.set_title('K Means - {} Clusters'.format(n_clusters))\n",
    "    x_label = ax.set_xlabel(x_label)\n",
    "    y_label = ax.set_ylabel(y_label)\n",
    "    \n",
    "    # Set the x- and y-axis limits using the padded minimum and maximum values\n",
    "    xlim = ax.set_xlim((x_min,x_max))\n",
    "    ylim = ax.set_ylim((y_min,y_max))\n",
    "    \n",
    "print 'DrawClusters() is ready to use!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 | Exercise\n",
    "\n",
    "### Quiz 1: Clustering Features \n",
    "\n",
    "**Create** a scatterplot of the data (`Salary` vs `Exercised Stock Option`), then look at the resulting figure. What clusters you would expect to arise from this data if 2 clusters are created? That is, how would you partition the data into two clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a scatter plot with 'Salary' on x-axis and 'Exercised Stock Option' on y-axis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2: Deploying Clustering \n",
    "\n",
    "**Run** the cell below, which will perform k-means clustering on the data using only the `salary` and `exercised_stock_options` features. Look at the resulting clusters -- because we're only using two features, we can also plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = False,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 3: Clustering with 3 Features\n",
    "\n",
    "**Run** the cell below to add a third feature to features_list, `total_payments`. The clustering is now performed using 3 input features instead of 2 (obviously we can still only visualize the original 2 features, `salary` and `exercised_stock_options`). We also can't visualize the decision boundary anymore, because the points all have different values for the `total_payments` feature. Compare the clusterings to those you obtained with 2 input features. Do any points switch clusters? How many? This new clustering, using 3 features, couldn’t have been guessed by eye -- it was the k-means algorithm that identified it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\",\"total_payments\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = False,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 4: Stock Option Range\n",
    "\n",
    "We're going to cover [feature scaling](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html), a type of preprocessing that you should perform before some classification and regression tasks. Here’s a general outline of what feature scaling does.\n",
    "\n",
    "What are the **maximum** and **minimum** values taken by the `exercised_stock_options` feature used in this example? \n",
    "\n",
    "In one of the preprocessing steps, all `NaN` entries in `enron_df` were changed to zeroes. We do this because all features passed into `sklearn` classifiers must be numeric. So, to answer this question, you may want to look at the original data *before* this preprocessing step was performed. To help with this task, **create** the data frame `df` from the `enron_data` dictionary without imputating the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a dataframe from Enron data dictionary without imputing the missing value\n",
    "\n",
    "\n",
    "print 'DataFrame df has been created!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find out the maximum and minimum values taken by the exercised_stock_options\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 5: Salary Range\n",
    "\n",
    "What are the **maximum** and **minimum** values taken by the `salary` feature used in this example? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find out the maximum and minimum values taken by the salary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 6: Clustering Changes\n",
    "\n",
    "**Run** the cell below to plot the original two clusters, with the features `salary` and `exercised_stock_options`. Note that the features are not yet scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = ['salary', 'exercised_stock_options'],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = False,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **run** the cell below to do simple feature rescaling, mapping the original ranges of `exercised_stock_options` and `salary` onto the interval [0, 1]. You should find that some of the points change clusters! You should also find that these clusters are not as stable as in the previous examples. **Run** the cell multiple times. You should find that the reported clusters are sometimes different, depending on where the centroids were initialized for k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = ['salary', 'exercised_stock_options'],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = True,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 7: Further Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: k-means clustering with 7 clusters, rescaled \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: k-means clustering with 3 clusters, different features, rescaled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: k-means clustering with 3 clusters, different features, rescaled\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd]",
   "language": "python",
   "name": "conda-env-mlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
