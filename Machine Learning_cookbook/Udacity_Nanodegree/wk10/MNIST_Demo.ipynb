{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 10. Digit Recognition using TensorFlow and Keras\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "  - Get familar with TensorFlow and Keras\n",
    "  - Built neural networks using TensorFlow and Keras to solve a multiclass classification problem\n",
    "  \n",
    "### Prerequisites\n",
    "  - [numpy](http://www.scipy.org/scipylib/download.html)  \n",
    "  - [matplotlib](http://matplotlib.org/index.html)  \n",
    "  - [tensorflow](https://www.tensorflow.org)\n",
    "  - [keras](https://keras.io) \n",
    "  \n",
    "### Installation  \n",
    "If you haven't installed TensorFlow and Keras, run the commands below for installation:  \n",
    "  - Install TensorFlow: `pip install tensorflow`  \n",
    "  - Install Keras: `pip install keras` (It requires either tensorflow or theano installation)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 | TensorFlow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowâ„¢ is an open source software library for numerical computation using **data flow graphs**. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them.   \n",
    "\n",
    "<img src=\"./imgs/graph.png\" width=\"400px\">\n",
    "\n",
    "The flexible architecture allows you to break up the graph into several chunks and run them in parallel across multiple CPUs or GPUs in a desktop, server, or mobile device with a single API. TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Your First Graph and Running it in a Session  \n",
    "\n",
    "The following code creates the graph represented above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out x, y, and f\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not getting the output we expect! This is because this code actually does not perform any computation, even though it looks like it does. It just creates a computation graph. In fact, even the variables are not initialized yet. To evaluate this graph, we need to open a TensorFlow **session** and use it to intialize the variables and evaluate `f`. A TensorFlow session takes care of placing the operations onto devices such as CPUs and GPUs and running them, and it holds all the variable values.   \n",
    "\n",
    "The following code creates a session, initializes the variables, and evaluates f, and then closes the session to free up resources.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One downside of the above code is that we keep repeating `sess.run()`. There is a better way as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `with` block, the session is set as the default session. Calling `x.initializer.run()` is equivalent to calling `tf.get_default_session().run(x.initializer)`. Similarly, `f.eval()` is equivalent to calling `tf.get_default_session().run(f)`. This makes the code easier to read. Moreover, the session is automatically closed at the end of the block. \n",
    "\n",
    "Instead of manually running the initializer for every single variable, we can use the `global_variables_initializer()` function. Note that it does not actually perform the initialization immediately, but rather creates a node in the graph that will initialize all variables when it run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside Jupyter or within a Python shell, we can also create an `InteractiveSession`. The only difference from a regular `Session` is that when an `InteractiveSession` is created, it automatically sets itself as the default session, so we don't need to use a `with` block. But you do need to close the session manually when you are done with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a TensorFlow program is typically split into two parts: **the first part builds a computation graph, and the decond part runs it**. Writing and running programs in TensorFlow has the following steps:  \n",
    "\n",
    "1. Create Tensors (variables) that are not yet executed/evaluated.   \n",
    "2. Write operations between those Tensors.  \n",
    "3. Initialize Tensors.  \n",
    "4. Create a Session.  \n",
    "5. Run the Session. This will run the operations you'd written above.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Graphs \n",
    "\n",
    "Any node you create is automatically added to the default graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, this is fine but sometimes you may want to manage multiple independent graphs. You can do this by creating a new Graph and temporarily making it the default graph inside a `with` block, as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll also have to know about **placeholders**. A placeholder is an object whose value you can specify later. To specify values for a placeholder, you can pass in values by using a \"feed dictionary\" (`feed_dict` variable). Below, we create a placeholder for x. This allows us to pass in a number later when we run the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first define x, you don't have to specify a value for it. A placeholder is simply a variable that you will assign data to only later, when running the session. We say that you feed data to these placeholders when running the session.  \n",
    "\n",
    "Here's what's happening: When you specify the operations needed for a computation, you are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values you will specify only later. Finally, when you run the session, you are telling TensorFlow to execute the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network for MNIST Digit Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **MNIST** database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.  \n",
    "\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. There have been a number of scientific papers on attempts to achieve the lowest error rate; one paper, using a hierarchical system of convolutional neural networks, manages to get an error rate on the MNIST database of 0.23 percent. The original creators of the database keep a list of some of the methods tested on it. In their original paper, they use a support vector machine to get an error rate of 0.8 percent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def preview_tf_mnist(n):\n",
    "    \"\"\"function to view the training data\"\"\"\n",
    "    plt.imshow(mnist.train.images[n].reshape(28, 28), cmap='gray')\n",
    "    print('True Label:', np.argmax(mnist.train.labels[n]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Label:', 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLYwYCdNdBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d960510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_tf_mnist(121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple neural network (one without hidden layer as shown below) for this task. The code below builds such a neural network with TensorFlow. \n",
    "\n",
    "<img src=\"./imgs/nn.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new tensorflow session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create placeholders for inputs and outputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # initialize weight as zero\n",
    "b = tf.Variable(tf.zeros([10])) # initialize bias as zero\n",
    "\n",
    "# initialize variables into session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# tf.matmul: matrix multiplication\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost function \n",
    "# tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "# tf.nn.softmax_cross_entropy_with_logits: Computes softmax cross entropy between `logits` and `labels` \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Descent optimizer\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the neural net for 1000 iterations\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(100) # mini-batch\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9181)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance\n",
    "correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not too bad. We obtain 92% accuracy for a 10 class classification problem in less than 15 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Takeaways\n",
    "\n",
    "- Tensorflow is a programming framework used in deep learning  \n",
    "- The two main object classes in tensorflow are Tensors and Operators. When you code in tensorflow you have to take the following steps:  \n",
    "    1. Create a graph containing Tensors (Variables, Placeholders ...) and Operations (tf.matmul, tf.add, ...)  \n",
    "    2. Create a session  \n",
    "    3. Initialize the session  \n",
    "    4. Run the session to execute the graph  \n",
    "- You can execute the graph multiple times\n",
    "- The backpropagation and optimization is automatically done when running the session on the \"optimizer\" object  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 | Keras \n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "  - Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "  - Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "  - Runs seamlessly on CPU and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the same neural network with Keras and see how it compares with TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define the model architecture, the first step is to declare a sequential model format. `Sequential` model type is simply a linear stack of neural network layers. Then, we can declare the input layer. Here, `Dense` is one of Keras' core layers. It is the regular densely-connected neural network layer. We can simply add more layers to our model like we're building legos using `model.add()`. Finally, we can define the loss function and the optimizer, and then we'll be ready to train it.\n",
    "\n",
    "We can view the model architecture using `model.summary()`. \n",
    "\n",
    "Note that in actual R&D work, researchers will spend a considerable amount of time studying model architectures. But as we're just starting out, we can just replicate proven architectures from academic papers or use existing examples. Here's a list of [example implementations in Keras](https://github.com/fchollet/keras/tree/master/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # declare a sequential model format \n",
    "model.add(Dense(10, input_dim=784, activation='softmax')) # declare the input layer\n",
    "sgd = SGD(lr=0.5) # define optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) # configures the learning process\n",
    "print(model.summary()) # check the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.4000 - acc: 0.8852 - val_loss: 0.2954 - val_acc: 0.9188\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.3112 - acc: 0.9123 - val_loss: 0.2875 - val_acc: 0.9171\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.2952 - acc: 0.9168 - val_loss: 0.2968 - val_acc: 0.9155\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.2879 - acc: 0.9193 - val_loss: 0.2826 - val_acc: 0.9179\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.2817 - acc: 0.9197 - val_loss: 0.2869 - val_acc: 0.9194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1286b4b90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trains the model for a fixed number of epochs\n",
    "model.fit(mnist.train.images, mnist.train.labels, batch_size=100, epochs=5, \n",
    "          validation_data=(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9194)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance\n",
    "score = model.evaluate(mnist.test.images, mnist.test.labels, verbose=0)\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get the same performance but with half amount of code. Building neural networks in Keras is just as easy as scikit-learn. In fact, keras provides an interface with scikit-learn, so that you can use neural networks just like any other ML algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE \n",
    "\n",
    "Use Keras to build a more complicated neural network. For example, the neural network built with the code below has one hidden layers. Run the cells below to see whether the performance improves. Build your own neural network. What is the architecture of your new model and what is the performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # declare a sequential model format \n",
    "model.add(Dense(64, input_dim=784, activation='relu')) # declare the input layer\n",
    "model.add(Dense(10, input_dim=64, activation='softmax')) # declare the hidden layer\n",
    "sgd = SGD(lr=0.5) # define optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) # configures the learning process\n",
    "print(model.summary()) # check the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 1s - loss: 0.3092 - acc: 0.9059 - val_loss: 0.1562 - val_acc: 0.9533\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 1s - loss: 0.1417 - acc: 0.9574 - val_loss: 0.1409 - val_acc: 0.9568\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 1s - loss: 0.1023 - acc: 0.9693 - val_loss: 0.1017 - val_acc: 0.9673\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 1s - loss: 0.0827 - acc: 0.9748 - val_loss: 0.0952 - val_acc: 0.9702\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.0688 - acc: 0.9783 - val_loss: 0.0894 - val_acc: 0.9709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1286e2f10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(mnist.train.images, mnist.train.labels, batch_size=100, epochs=5, \n",
    "          validation_data=(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.97089999999999999)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(mnist.test.images, mnist.test.labels, verbose=0)\n",
    "print('Accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd]",
   "language": "python",
   "name": "conda-env-mlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
