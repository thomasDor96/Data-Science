{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 9. Porto Seguro’s Safe Driver Prediction - A Kaggle Competition\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "  - Get familiar with the process of creating machine learning solutions to a real problem  \n",
    "  - Practice skills such as data analysis and visualization, model building, evaluation and optimization on a real-world dataset\n",
    "  \n",
    "### Prerequisites\n",
    "  - [matplotlib](http://matplotlib.org/index.html)  \n",
    "  - [numpy](http://www.scipy.org/scipylib/download.html)  \n",
    "  - [pandas](http://pandas.pydata.org/getpandas.html)  \n",
    "  - [sklearn](http://scikit-learn.org/stable/install.html)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Overview\n",
    "\n",
    "> **More details about the competition can be found [here](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction).**\n",
    "\n",
    "Nothing ruins the thrill of buying a brand new car more quickly than seeing your new insurance bill. The sting’s even more painful when you know you’re a good driver. It doesn’t seem fair that you have to pay so much if you’ve been cautious on the road for years.\n",
    "\n",
    "Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company’s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.\n",
    "\n",
    "In this competition, you’re challenged to build a model that **predicts the probability that a driver will initiate an auto insurance claim in the next year** - thus a *supervised binary classification* problem. While Porto Seguro has used machine learning for the past 20 years, they’re looking to Kaggle’s machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.  \n",
    "\n",
    "*Note:* The problem is well defined for you here, but in reality, you may be the one to frame the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Steps\n",
    "\n",
    "We can break the process into separate steps. You can use the links below to navigate the notebook.\n",
    "\n",
    "[Step 0](#step0): Get the Data    \n",
    "[Step 1](#step1): Data Exploration  \n",
    "[Step 2](#step2): Prepare Data for Machine Learning Algorithms  \n",
    "[Step 3](#step3): Select and Train a Model  \n",
    "[Step 4](#step4): Fine Tune the Model  \n",
    "[Step 5](#step5): Generate Submission File\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step0'></a>\n",
    "## Step 0: Get the Data  \n",
    "\n",
    "### Download the Data Files\n",
    "\n",
    "The first step is to download the data. Go to the [competition page]() and navigate to the data tab. You can see the **\"download\"** button in the page. Note that you will need to log in to your Kaggle account and click the **\"I understand and accept\"** button. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find descriptions about the files and data from the data page. Below is the information taken from that page:  \n",
    "\n",
    "> **Data Description:** In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., `ind`, `reg`, `car`, `calc`). In addition, feature names include the postfix **`bin`** to indicate binary features and **`cat`** to indicate categorical features. Features without these designations are either continuous or ordinal. Values of **-1** indicate that the feature was missing from the observation. The target columns signifies whether or not a claim was filed for that policy holder.  \n",
    "\n",
    "> **File Descriptions:** **`train.csv`** contains the training data, where each row corresponds to a policy holder, and the target columns signifies that a claim was filed. **`test.csv`** contains the test data. **`sample_submission.csv`** is the submission file showing the correct format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**   \n",
    "Download the files following the instructions above. Unzip the downloaded files. Create a folder named **`data`** in the directory where this notebook is. Place the unzipped files in the **`data/`** folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data into Pandas \n",
    "\n",
    "Now you should have 3 csv files in the **`data/`** folder. Read them into Pandas dataframe and take a quick look at the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** \n",
    "Use the following cells (feel free to add more if needed) to read the data and take a quick look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read './data/train.csv' \n",
    "train_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find out the shape of the data, what are the features, what is the name of the target variable, \n",
    "# what are the data types, and get a statistical description of the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optional:** You will notice that the data types include *int64* and *float64*. One thing you can do to reduce the memory usage of the dataframe is to convert the data types into *int32* and *float32*. Can you write a function to perform this task?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read './data/test.csv' \n",
    "test_df = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what does the test data look like? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read './data/sample_submission.csv' \n",
    "submission_df = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what should your submission format look like?  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a validation set (20%)  \n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**  \n",
    "Why do we want to create a validation set now?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Data Exploration  \n",
    "\n",
    "Make sure you have put aside a validation set and you only explore the training set. Also, if the training set is very large, you may want to sample an exploration set to speed up the exploration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Features  \n",
    "\n",
    "**TODO**  \n",
    "Use the code cells below (feel free to add more if needed) and create at least 3 visualizations using `matplotlib` or `seaborn`. What insights can you get from the visualizations?  \n",
    "\n",
    "*Hint:* distributions of individual features, correlations between features, correlation matrix...also, for classification problem, you might want to also check the class distribution  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualization 1: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualization 2:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualization 3: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Prepare Data for Machine Learning Algorithms   \n",
    "\n",
    "Now, it is time to prepare the data for machine learning algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning  \n",
    "\n",
    "**TODO:** \n",
    "In this dataset, missing values are encoded as `-1`. Find out the percentage of missing values for each feature. What strategies would you use to deal with the missing values? Implement your strategies.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables  \n",
    "\n",
    "**TODO:**  \n",
    "Convert categorical values into dummy variables either by `get_dummies()` from pandas or `OneHotEncoder()` from scikit-learn. What happens if some values for some categorical features only present in the training or only in the test sets? Implement your strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling   \n",
    "\n",
    "Feature scaling is one of the most important transformations you need to apply because, with few exceptions, machine learning algorithms don't perform well when the input numerical features have very different scales. Some examples of algorithms where feature scaling matters are:\n",
    "\n",
    "- k-nearest neighbors with an Euclidean distance measure if want all features to contribute equally  \n",
    "- k-means (for reasons similar to k-nearest neighbors) \n",
    "- logistic regression, SVMs, perceptrons, neural networks etc. if you are using gradient descent/ascent-based optimization, because otherwise some weights will be updated much faster than others   \n",
    "- linear discriminant analysis, principal component analysis, kernel principal component analysis since you want to find directions of maximizing the variance; you want to have features on the same scale since otherwise you’d emphasize variables on \"larger measurement scales\" more.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**  \n",
    "Perform feature scaling on the dataset. Should we use standardization or min-max scaling? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Feature Transformation  \n",
    "\n",
    "**QUESTION:**  \n",
    "Do you think there are other feature transformations necessary, e.g., PCA?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Select and Train a Model  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate on one Model \n",
    "\n",
    "**TODO:**  \n",
    "Select and train one model. Why do you select the model? What is the training score and what is the validation score? Is this the final model you would choose for fine tuning?     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "**TODO:**  \n",
    "Select 3-5 different different algorithms, and use cross-validation to compare the performance and running time. Which model would you choose for further fine tuning?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=step4></a>\n",
    "## Step 4: Fine Tune the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search  \n",
    "\n",
    "**TODO:**\n",
    "Optimize the chosen model from the previous step by Grid Search. Do you think Randomized Search would be better in this case? What are the training and test scores after model optimization?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=step5></a>\n",
    "## Step 5: Generate Submission File  \n",
    "\n",
    "**TODO:**  \n",
    "Now you can make predictions with the above model on the instances in **`test_df`** and generate a submission file. You can submit your file to Kaggle. What is your public leader board score and ranking?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd]",
   "language": "python",
   "name": "conda-env-mlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
