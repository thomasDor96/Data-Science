{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 3. Build Regression Models\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "- Implement regression models to predict housing price  \n",
    "    - Perform exploratory analysis with pandas, matplotlib, and seaborn\n",
    "    - Build univariate and multivariate linear regression models     \n",
    "    - Build decision tree regression models\n",
    "- Evaluate the model performance  \n",
    "    - Calculate performance metrics\n",
    "    - Tune the model complexity and understand the performance change\n",
    "  \n",
    "### Prerequisites   \n",
    "\n",
    " - You should have the following python packages installed:\n",
    "    - [numpy](http://www.scipy.org/scipylib/download.html)\n",
    "    - [pandas](http://pandas.pydata.org/getpandas.html)\n",
    "    - [matplotlib](http://matplotlib.org/index.html)\n",
    "    - [seaborn](http://seaborn.pydata.org) \n",
    "    - [sklearn](http://scikit-learn.org/stable/install.html)\n",
    " - If you're rusty on basic python programming and exploratory data analysis, check out the [Jupyter notebooks from week 1](https://github.com/yanfei-wu/Udacity_connect/tree/master/wk1). If you are not familar with `sklearn`'s model building workflow, check out the [Jupyter notebook from week 2](https://github.com/yanfei-wu/Udacity_connect/tree/master/wk2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Getting Started\n",
    "\n",
    "As usual, we start by importing some useful libraries and modules (make sure you have `scikit-learn` installed) and reading the dataset into pandas. And note that it is always a good idea to take a quick look at the dataset using the DataFrame's `head()`, `info()`, or `describe()` methods. \n",
    "\n",
    "**Run** the cells below to import the libraries, read the data, and take a quick look at the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set maximum rows to display\n",
    "pd.options.display.max_rows = 15 # default is 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data \n",
    "data = pd.read_csv('./data/home_data.csv')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this programming exercise, we are going to use a simple housing dataset with 7 features:  \n",
    "- '`bedrooms`': number of beedrooms\n",
    "- '`bathrooms`': number of bathrooms\n",
    "- '`sqft_living`': living area size in square feet\n",
    "- '`sqft_lot`': lot size in square feet  \n",
    "- '`sqft_basement`': size of basement in square feet   \n",
    "- '`floors`': number of floors  \n",
    "- '`condition`': condition of the home coded with integers  \n",
    "\n",
    "The label (or target variable) we are going to predict is the '`price`'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Exploratory Data Analysis \n",
    "\n",
    "So far you should have a rough idea of the basic structure of the data. Remember, when working on a machine learning problem, before you jump into the model building, you should always explore you dataset to gain more insights. \n",
    "\n",
    "\n",
    "#### EXERCISE\n",
    "By now, you should have some exploratory data analysis tools in your toolbox. I will leave it to you to get some in-depth understanding of the dataset you are going to build a model with. \n",
    "\n",
    "> **Something you might want to explore:** \n",
    "    > - Distribution of individual features \n",
    "    > - Correlation between pairs of features (You will find the DataFrame's `corr()` method useful. Also, check out `seaborn`'s `pairplot()` method.)\n",
    "    > - (OPTIONAL) Experiment with feature combinations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Data for Model Building\n",
    "\n",
    "After you have explored your dataset, you usually have to do some preprocessing and cleaning steps to prepare the dataset for your machine learning algorithms. For example, as you learned from last week's tutorial, you should check whether there are missing values in your dataset. If so, there are different strategies for dealing with them (e.g., dropping the feature or some form of imputation). In cases when your dataset has categorical features, you should convert them to numerical variables, either by mapping the categorical features to numerical values, or use *one-hot encoding* to turn the features into dummy variables. \n",
    "\n",
    "**Sometimes, it is also a good idea to scale the features because some machine learning algorithms do not perform well when the input numerical variables have different scales.** For example, in algorithms that calculate the distance between two points by the Euclidean distance, the distance will be governed by the feature with broad range of values. Also, for regularized linear models (Ridge, Lasso, and ElasticNet), normalization is very important because the scale of the variable affects how much regularization will be applied to that specific variable. (More on this [Wikipedia](https://en.wikipedia.org/wiki/Feature_scaling) page for feature scaling). \n",
    "\n",
    "For now, we will just use the data as it is and build linear regression models and decision tree models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training, Testing, and Model Evaluation\n",
    "\n",
    "### 1. Univariate Linear Regression \n",
    "\n",
    "Univariate linear regression is an approach for predicting a quantitative response using a single feature (or \"predictor\" or \"input variable\"). For example, we can use `sqft_living` as our feature to predict `price`. However, we know that this feature along probably does not have enough predictive power for the home price. We are only using this as an example to demonstrate linear regression with `sklearn`. \n",
    "\n",
    "But, first, let's split our data into training and test sets using `train_test_split()`. For more impormation about `train_test_split()`, read the [documentation about the method](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). In Jupyter notebook, a handy shortcut to view the documentation is to use **shift + tab** with your cursor inside the parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# Split the original dataset into training and test data sets\n",
    "# Note that we split the original dataset instead of `X` (features) and `y` (label) arrays \n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=21)\n",
    "\n",
    "# Take a look at the first few rows of the training features and classes\n",
    "display(train_set.head())\n",
    "display(test_set.head())\n",
    "\n",
    "# Verify that the data sets were split 80% training and 20% testing\n",
    "print 'The number of instances in the original data: {}'.format(data.shape[0])\n",
    "print 'The number of instances in the training set: {}'.format(train_set.shape[0])\n",
    "print 'The number of instances in the test set: {}'.format(test_set.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's separate features and label\n",
    "X_train = train_set['sqft_living'].values.reshape(-1, 1) # need do reshape if data has a single feature\n",
    "y_train = train_set['price']\n",
    "X_test = test_set['sqft_living'].values.reshape(-1, 1)\n",
    "y_test = test_set['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our model with `sklean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# CREATE regression object... in this example\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# TRAIN the object using the method .fit()\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "# PREDICT labels for the train and test set using the method .predict()\n",
    "y_pred_train = lreg.predict(X_train)\n",
    "y_pred_test  = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intepreting the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train, y_train, '.', X_train, y_pred_train, '-')\n",
    "plt.xlabel('Living Area Size (sqft)')\n",
    "plt.ylabel('Home Price (USD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Intercept of the regression line is %f.' % lreg.intercept_\n",
    "print 'Slope of the regression line is %f.' % lreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION: What does the coefficients mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** the above data shows the so-called [heterosedasticity](https://en.wikipedia.org/wiki/Heteroscedasticity), i.e., the variability of a variable is unequal across the range of values of a second variable that predicts it. In the above case, the regression model is highly inconsistent when it predicts high values of `sqft_living`. Read more about how heterosedasticity would affect regression in this [Quora post](https://www.quora.com/How-would-homo-heteroskedasticity-affect-regression-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print 'Root mean squared error for training set: %.3f' % np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print 'Root mean squared error for test set: %.3f' % np.sqrt(mean_squared_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE: Calculate regression performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: CALCULATE r squared\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: CALCULATE mean absolute error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's separate features and label\n",
    "X_train = train_set.drop('price', axis=1)\n",
    "y_train = train_set['price']\n",
    "X_test = test_set.drop('price', axis=1)\n",
    "y_test = test_set['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE: Implement multivariate linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: CREATE regression object\n",
    "\n",
    "\n",
    "# TODO: TRAIN the object using the method .fit()\n",
    "\n",
    "\n",
    "# TODO: PREDICT labels for the train and test set using the method .predict()\n",
    "\n",
    "\n",
    "# TODO: CALCULATE performance metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree Regression  \n",
    "\n",
    "Linear regression does not do a very good job in predicting the home price with the given features. Let's see if a different algorithm could do any better. Remember we built a decision tree classifier last week to predict whether a given Titanic passenger survived or not. Decision tree algorithm can also be used for regression problem. It works very similarly as in classification problems by splitting but now the leaf of the tree represents a numerical value instead of a class label. I will let you to work through the unfinished code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE: Finish the implementation of a decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# TODO: CREATE regression object\n",
    " \n",
    "\n",
    "# TODO: TRAIN the object using the method .fit()\n",
    "\n",
    "\n",
    "# TODO: PREDICT labels for the train and test set using the method .predict()\n",
    "\n",
    "\n",
    "# TODO: CALCULATE performance metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE: Tune the complexity of the model and compare the model performance. What is the optimal complexity for a decision tree regression model in this case? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE (OPTIONAL) : Can you plot a complexity plot showing train and test performance as a function of model complexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd]",
   "language": "python",
   "name": "conda-env-mlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
